{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHRF1Cl5+LwN/k4Mi4gkGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Modak12/GestureControl/blob/main/2dconv%2BRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with CONV2D +RNN"
      ],
      "metadata": {
        "id": "CqktFuAqkBEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UZqumIucWVrd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ],
      "metadata": {
        "id": "Oj8G0P3Lo9Rf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAWj7gg6pFl0",
        "outputId": "d60b3e86-81d0-41a7-d467-0b5b21a86201"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = np.random.permutation(open('/content/drive/My Drive/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/drive/My Drive/Project_data/val.csv').readlines())\n",
        "batch_size = 10 #experiment with the batch size"
      ],
      "metadata": {
        "id": "15y-nYPPpI53"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_doc))\n",
        "print(len(val_doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq_sY3iPpviJ",
        "outputId": "4258230e-ceba-4c2a-ae9c-ee20d61da756"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "663\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = list(train_doc)[:50]\n",
        "val_doc = list(val_doc)[:10]\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "v14zlwi4tNCE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_doc))\n",
        "print(len(val_doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC1Iy8Bs14mY",
        "outputId": "5dc7181d-be2a-41b2-ffc5-bbd58b9b9467"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimension={\n",
        "    'img_idx' : [x for x in range(30)],\n",
        "    'y' : 120,\n",
        "    'z' : 120\n",
        "}"
      ],
      "metadata": {
        "id": "vLbwX8wsp21s"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(source_path, folder_list, batch_size, dimensions=dimension):\n",
        "\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "\n",
        "    img_idx = dimensions['img_idx']\n",
        "    x = len(img_idx)\n",
        "    y = dimensions['y']\n",
        "    z = dimensions['z']\n",
        "\n",
        "    while True:\n",
        "\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(train_doc)//batch_size # calculate the number of batches\n",
        "        print(\"Number of batches : \",num_batches)\n",
        "\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    image = resize(image,(y,z))\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = (image[:,:,0])/255.0 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (image[:,:,1])/255.0 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (image[:,:,2])/255.0 #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        if(len(t) % batch_size):\n",
        "          rem_batches = len(t) % batch_size\n",
        "          print(\"Remaining batches : \",rem_batches)\n",
        "          rem_batch_data = np.zeros((rem_batches,x,y,z,3))\n",
        "          batch_labels = np.zeros((rem_batches,5))\n",
        "          for folder in range(rem_batches): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*rem_batches)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*rem_batches)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    image = resize(image,(y,z))\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "                    rem_batch_data[folder,idx,:,:,0] = (image[:,:,0])/255 #normalise and feed in the image\n",
        "                    rem_batch_data[folder,idx,:,:,1] = (image[:,:,1])/255 #normalise and feed in the image\n",
        "                    rem_batch_data[folder,idx,:,:,2] = (image[:,:,2])/255 #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*rem_batches)].strip().split(';')[2])] = 1\n",
        "          yield rem_batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n"
      ],
      "metadata": {
        "id": "XpN5J0Drp68j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "\n",
        "train_path = '/content/drive/My Drive/Project_data/train'\n",
        "val_path = '/content/drive/My Drive/Project_data/val'\n",
        "\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "\n",
        "num_epochs = 1 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cigefV4A27yY",
        "outputId": "bb7d158b-8c97-4bea-b66c-18f133d45bb9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 50\n",
            "# validation sequences = 10\n",
            "# epochs = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing generative\n",
        "test_gen = generator(train_path, train_doc, 1)\n",
        "d = next(test_gen)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN0AZtVz3Hum",
        "outputId": "e2f53fc2-25d6-4664-c9a0-7effdd5ae0ff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/drive/My Drive/Project_data/train ; batch size = 1\n",
            "Number of batches :  50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-7764a8e080dd>:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "input_shape = (30, 120, 120, 3)"
      ],
      "metadata": {
        "id": "nME32Fa9lh1-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D, MaxPooling2D, GlobalAveragePooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#write your model here\n",
        "sample_shape = (30, 120, 120, 3)\n",
        "\n",
        "no_classes = 5\n",
        "\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
        ")\n",
        "model.add(TimeDistributed(\n",
        "    MaxPooling2D((2,2)))\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(64, (3,3), activation='relu'))\n",
        ")\n",
        "model.add(TimeDistributed(\n",
        "    MaxPooling2D((2,2)))\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(TimeDistributed(\n",
        "    Conv2D(128, (3,3), activation='relu'))\n",
        ")\n",
        "model.add(TimeDistributed(\n",
        "    MaxPooling2D((2,2)))\n",
        ")\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(GlobalAveragePooling3D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "9bg_9qQ1lXLy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = optimizers.Adam(lr=0.01) #write your optimizer\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-LYK18BlplN",
        "outputId": "50160be3-cd33-43b7-dad8-c46abad83154"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_12 (TimeD  (None, 30, 118, 118, 32   896       \n",
            " istributed)                 )                                   \n",
            "                                                                 \n",
            " time_distributed_13 (TimeD  (None, 30, 59, 59, 32)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 30, 59, 59, 32)    128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_14 (TimeD  (None, 30, 57, 57, 64)    18496     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_15 (TimeD  (None, 30, 28, 28, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 30, 28, 28, 64)    256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " time_distributed_16 (TimeD  (None, 30, 26, 26, 128)   73856     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_17 (TimeD  (None, 30, 13, 13, 128)   0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 30, 13, 13, 128)   512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " global_average_pooling3d_2  (None, 128)               0         \n",
            "  (GlobalAveragePooling3D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 129477 (505.77 KB)\n",
            "Trainable params: 128517 (502.02 KB)\n",
            "Non-trainable params: 960 (3.75 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ],
      "metadata": {
        "id": "ng17QxwX3jmB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = '2d_model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4) # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-shGCNM3nCE",
        "outputId": "273ca08c-d70b-42c8-f911-d8b1e48d8b4c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ],
      "metadata": {
        "id": "Qc5xwpRB3pE0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSBIFCMv3roa",
        "outputId": "1651b02b-8f3b-40ca-80d4-7efa266f3bbc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-7f8f9d39394d>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
            "<ipython-input-47-7764a8e080dd>:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/drive/My Drive/Project_data/train ; batch size = 10\n",
            "Number of batches :  5\n",
            "3/5 [=================>............] - ETA: 26s - loss: 2.4710 - categorical_accuracy: 0.1667Number of batches :  5\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.0166 - categorical_accuracy: 0.2800 Source path =  /content/drive/My Drive/Project_data/val ; batch size = 10\n",
            "Number of batches :  5\n",
            "\n",
            "Epoch 1: saving model to 2d_model_init_2024-03-2206_11_05.676446/model-00001-2.01663-0.28000-1.63390-0.10000.h5\n",
            "5/5 [==============================] - 79s 15s/step - loss: 2.0166 - categorical_accuracy: 0.2800 - val_loss: 1.6339 - val_categorical_accuracy: 0.1000 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2bc66edb70>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}